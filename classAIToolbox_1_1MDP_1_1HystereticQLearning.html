<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AIToolbox: AIToolbox::MDP::HystereticQLearning Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AIToolbox
   </div>
   <div id="projectbrief">A library that offers tools for AI problem solving.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classAIToolbox_1_1MDP_1_1HystereticQLearning.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classAIToolbox_1_1MDP_1_1HystereticQLearning-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">AIToolbox::MDP::HystereticQLearning Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>This class represents the Hysteretic <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm.">QLearning</a> algorithm.  
 <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="HystereticQLearning_8hpp_source.html">AIToolbox/MDP/Algorithms/HystereticQLearning.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a3fe689ebd4ab765d33d42dd3cee8cf0d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a3fe689ebd4ab765d33d42dd3cee8cf0d">HystereticQLearning</a> (size_t S, size_t A, double discount=1.0, double alpha=0.1, double beta=0.01)</td></tr>
<tr class="memdesc:a3fe689ebd4ab765d33d42dd3cee8cf0d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic constructor.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a3fe689ebd4ab765d33d42dd3cee8cf0d">More...</a><br /></td></tr>
<tr class="separator:a3fe689ebd4ab765d33d42dd3cee8cf0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c8791dbbe638a2c28c19cdc7faa254b"><td class="memTemplParams" colspan="2">template&lt;IsGenerativeModel M&gt; </td></tr>
<tr class="memitem:a8c8791dbbe638a2c28c19cdc7faa254b"><td class="memTemplItemLeft" align="right" valign="top">&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a8c8791dbbe638a2c28c19cdc7faa254b">HystereticQLearning</a> (const M &amp;model, double alpha=0.1, double beta=0.01)</td></tr>
<tr class="memdesc:a8c8791dbbe638a2c28c19cdc7faa254b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic constructor.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a8c8791dbbe638a2c28c19cdc7faa254b">More...</a><br /></td></tr>
<tr class="separator:a8c8791dbbe638a2c28c19cdc7faa254b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa02544fb4e7edb44066eba3ae155fc46"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#aa02544fb4e7edb44066eba3ae155fc46">setPositiveLearningRate</a> (double a)</td></tr>
<tr class="memdesc:aa02544fb4e7edb44066eba3ae155fc46"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the learning rate parameter for positive updates.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#aa02544fb4e7edb44066eba3ae155fc46">More...</a><br /></td></tr>
<tr class="separator:aa02544fb4e7edb44066eba3ae155fc46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af20da362d91f0db3459e1c4bba65c18c"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#af20da362d91f0db3459e1c4bba65c18c">getPositiveLearningRate</a> () const</td></tr>
<tr class="memdesc:af20da362d91f0db3459e1c4bba65c18c"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function will return the currently set learning rate parameter for positive updates.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#af20da362d91f0db3459e1c4bba65c18c">More...</a><br /></td></tr>
<tr class="separator:af20da362d91f0db3459e1c4bba65c18c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac36a43e3a3f0c77bc7fa0fc906e16145"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#ac36a43e3a3f0c77bc7fa0fc906e16145">setNegativeLearningRate</a> (double b)</td></tr>
<tr class="memdesc:ac36a43e3a3f0c77bc7fa0fc906e16145"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the learning rate parameter for negative updates.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#ac36a43e3a3f0c77bc7fa0fc906e16145">More...</a><br /></td></tr>
<tr class="separator:ac36a43e3a3f0c77bc7fa0fc906e16145"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abb90f3deff71d74bd79c00c2a747a077"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#abb90f3deff71d74bd79c00c2a747a077">getNegativeLearningRate</a> () const</td></tr>
<tr class="memdesc:abb90f3deff71d74bd79c00c2a747a077"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function will return the currently set learning rate parameter for negative updates.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#abb90f3deff71d74bd79c00c2a747a077">More...</a><br /></td></tr>
<tr class="separator:abb90f3deff71d74bd79c00c2a747a077"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2fe053ebfbef4c5af8f9192a95945931"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a2fe053ebfbef4c5af8f9192a95945931">setDiscount</a> (double d)</td></tr>
<tr class="memdesc:a2fe053ebfbef4c5af8f9192a95945931"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the new discount parameter.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a2fe053ebfbef4c5af8f9192a95945931">More...</a><br /></td></tr>
<tr class="separator:a2fe053ebfbef4c5af8f9192a95945931"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab4fff4bccfa9da7dd327008b1f39719"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#aab4fff4bccfa9da7dd327008b1f39719">getDiscount</a> () const</td></tr>
<tr class="memdesc:aab4fff4bccfa9da7dd327008b1f39719"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the currently set discount parameter.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#aab4fff4bccfa9da7dd327008b1f39719">More...</a><br /></td></tr>
<tr class="separator:aab4fff4bccfa9da7dd327008b1f39719"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a78dea7a0d6abd24f5d306a97c0f51599"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a78dea7a0d6abd24f5d306a97c0f51599">stepUpdateQ</a> (size_t s, size_t a, size_t s1, double rew)</td></tr>
<tr class="memdesc:a78dea7a0d6abd24f5d306a97c0f51599"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function updates the internal QFunction using the discount set during construction.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a78dea7a0d6abd24f5d306a97c0f51599">More...</a><br /></td></tr>
<tr class="separator:a78dea7a0d6abd24f5d306a97c0f51599"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:addcfc61e6894692a4ea3f1fa38da2038"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#addcfc61e6894692a4ea3f1fa38da2038">getS</a> () const</td></tr>
<tr class="memdesc:addcfc61e6894692a4ea3f1fa38da2038"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of states on which <a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html" title="This class represents the Hysteretic QLearning algorithm.">HystereticQLearning</a> is working.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#addcfc61e6894692a4ea3f1fa38da2038">More...</a><br /></td></tr>
<tr class="separator:addcfc61e6894692a4ea3f1fa38da2038"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82f36579d713e440b74930bed39dd78a"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a82f36579d713e440b74930bed39dd78a">getA</a> () const</td></tr>
<tr class="memdesc:a82f36579d713e440b74930bed39dd78a"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of actions on which <a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html" title="This class represents the Hysteretic QLearning algorithm.">HystereticQLearning</a> is working.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a82f36579d713e440b74930bed39dd78a">More...</a><br /></td></tr>
<tr class="separator:a82f36579d713e440b74930bed39dd78a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a155dd01a024e942b97af2ff9459ac9d9"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a155dd01a024e942b97af2ff9459ac9d9">getQFunction</a> () const</td></tr>
<tr class="memdesc:a155dd01a024e942b97af2ff9459ac9d9"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns a reference to the internal QFunction.  <a href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html#a155dd01a024e942b97af2ff9459ac9d9">More...</a><br /></td></tr>
<tr class="separator:a155dd01a024e942b97af2ff9459ac9d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This class represents the Hysteretic <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm.">QLearning</a> algorithm. </p>
<p>This algorithm is a very simple but powerful way to learn the optimal QFunction for an <a class="el" href="namespaceAIToolbox_1_1MDP.html">MDP</a> model, where the transition and reward functions are unknown. It works in an offline fashion, meaning that it can be used even if the policy that the agent is currently using is not the optimal one, or is different by the one currently specified by the <a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html" title="This class represents the Hysteretic QLearning algorithm.">HystereticQLearning</a> QFunction.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm.">QLearning</a></dd></dl>
<p>The algorithm functions quite like the normal <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm.">QLearning</a> algorithm, with a small difference: it has an additional learning parameter, beta.</p>
<p>One of the learning parameters (alpha) is used when the change to the underlying QFunction is positive. The other (beta), which should be kept lower than alpha, is used when the change is negative.</p>
<p>This is useful when using <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm.">QLearning</a> for multi-agent RL where each agent is independent. A multi-agent environment is non-stationary from the point of view of a single agent, which is disruptive for normal <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm.">QLearning</a> and generally prevents it to learn to coordinate with the other agents well.</p>
<p>By assigning a higher learning parameter to transitions resulting in a positive feedback, the agent insulates itself from bad results which happen when the other agents take exploratory actions.</p>
<p>Bad results are still guaranteed to be discovered, since the learning parameter is still greater than zero, but the algorithm tries to focus on the good things rather than the bad.</p>
<p>If the beta parameter is equal to the alpha, this becomes standard <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm.">QLearning</a>. When the beta parameter is zero, the algorithm becomes equivalent to Distributed <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm.">QLearning</a>. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a3fe689ebd4ab765d33d42dd3cee8cf0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3fe689ebd4ab765d33d42dd3cee8cf0d">&#9670;&nbsp;</a></span>HystereticQLearning() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">AIToolbox::MDP::HystereticQLearning::HystereticQLearning </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>S</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>discount</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>beta</em> = <code>0.01</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic constructor. </p>
<p>The alpha learning rate must be &gt; 0.0 and &lt;= 1.0, otherwise the constructor will throw an std::invalid_argument.</p>
<p>The beta learning rate must be &gt;= 0.0 and &lt;= 1.0, otherwise the constructor will throw an std::invalid_argument. It can be zero.</p>
<p>Keep in mind that the beta parameter should be lower than the alpha parameter, although this is not enforced.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">S</td><td>The size of the state space. </td></tr>
    <tr><td class="paramname">A</td><td>The size of the action space. </td></tr>
    <tr><td class="paramname">discount</td><td>The discount to use when learning. </td></tr>
    <tr><td class="paramname">alpha</td><td>The learning rate for positive updates. </td></tr>
    <tr><td class="paramname">beta</td><td>The learning rate for negative updates. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a8c8791dbbe638a2c28c19cdc7faa254b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8c8791dbbe638a2c28c19cdc7faa254b">&#9670;&nbsp;</a></span>HystereticQLearning() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;IsGenerativeModel M&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">AIToolbox::MDP::HystereticQLearning::HystereticQLearning </td>
          <td>(</td>
          <td class="paramtype">const M &amp;&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>beta</em> = <code>0.01</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic constructor. </p>
<p>The alpha learning rate must be &gt; 0.0 and &lt;= 1.0, otherwise the constructor will throw an std::invalid_argument.</p>
<p>The beta learning rate must be &gt;= 0.0 and &lt;= 1.0, otherwise the constructor will throw an std::invalid_argument. It can be zero.</p>
<p>Keep in mind that the beta parameter should be lower than the alpha parameter, although this is not enforced.</p>
<p>This constructor copies the S and A and discount parameters from the supplied model. It does not keep the reference, so if the discount needs to change you'll need to update it here manually too.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The <a class="el" href="namespaceAIToolbox_1_1MDP.html">MDP</a> model that <a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html" title="This class represents the Hysteretic QLearning algorithm.">HystereticQLearning</a> will use as a base. </td></tr>
    <tr><td class="paramname">alpha</td><td>The learning rate of the <a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html" title="This class represents the Hysteretic QLearning algorithm.">HystereticQLearning</a> method. </td></tr>
    <tr><td class="paramname">beta</td><td>The learning rate for negative updates. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a82f36579d713e440b74930bed39dd78a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82f36579d713e440b74930bed39dd78a">&#9670;&nbsp;</a></span>getA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t AIToolbox::MDP::HystereticQLearning::getA </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the number of actions on which <a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html" title="This class represents the Hysteretic QLearning algorithm.">HystereticQLearning</a> is working. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of actions. </dd></dl>

</div>
</div>
<a id="aab4fff4bccfa9da7dd327008b1f39719"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab4fff4bccfa9da7dd327008b1f39719">&#9670;&nbsp;</a></span>getDiscount()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::MDP::HystereticQLearning::getDiscount </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the currently set discount parameter. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set discount parameter. </dd></dl>

</div>
</div>
<a id="abb90f3deff71d74bd79c00c2a747a077"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb90f3deff71d74bd79c00c2a747a077">&#9670;&nbsp;</a></span>getNegativeLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::MDP::HystereticQLearning::getNegativeLearningRate </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function will return the currently set learning rate parameter for negative updates. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set learning rate parameter for negative updates. </dd></dl>

</div>
</div>
<a id="af20da362d91f0db3459e1c4bba65c18c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af20da362d91f0db3459e1c4bba65c18c">&#9670;&nbsp;</a></span>getPositiveLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::MDP::HystereticQLearning::getPositiveLearningRate </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function will return the currently set learning rate parameter for positive updates. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set learning rate parameter for positive updates. </dd></dl>

</div>
</div>
<a id="a155dd01a024e942b97af2ff9459ac9d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a155dd01a024e942b97af2ff9459ac9d9">&#9670;&nbsp;</a></span>getQFunction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a>&amp; AIToolbox::MDP::HystereticQLearning::getQFunction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns a reference to the internal QFunction. </p>
<p>The returned reference can be used to build Policies, for example <a class="el" href="classAIToolbox_1_1MDP_1_1QGreedyPolicy.html" title="This class implements a greedy policy through a QFunction.">MDP::QGreedyPolicy</a>.</p>
<dl class="section return"><dt>Returns</dt><dd>The internal QFunction. </dd></dl>

</div>
</div>
<a id="addcfc61e6894692a4ea3f1fa38da2038"></a>
<h2 class="memtitle"><span class="permalink"><a href="#addcfc61e6894692a4ea3f1fa38da2038">&#9670;&nbsp;</a></span>getS()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t AIToolbox::MDP::HystereticQLearning::getS </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the number of states on which <a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html" title="This class represents the Hysteretic QLearning algorithm.">HystereticQLearning</a> is working. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of states. </dd></dl>

</div>
</div>
<a id="a2fe053ebfbef4c5af8f9192a95945931"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2fe053ebfbef4c5af8f9192a95945931">&#9670;&nbsp;</a></span>setDiscount()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::HystereticQLearning::setDiscount </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>d</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the new discount parameter. </p>
<p>The discount parameter controls the amount that future rewards are considered by <a class="el" href="classAIToolbox_1_1MDP_1_1HystereticQLearning.html" title="This class represents the Hysteretic QLearning algorithm.">HystereticQLearning</a>. If 1, then any reward is the same, if obtained now or in a million timesteps. Thus the algorithm will optimize overall reward accretion. When less than 1, rewards obtained in the presents are valued more than future rewards.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">d</td><td>The new discount factor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ac36a43e3a3f0c77bc7fa0fc906e16145"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac36a43e3a3f0c77bc7fa0fc906e16145">&#9670;&nbsp;</a></span>setNegativeLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::HystereticQLearning::setNegativeLearningRate </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>b</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the learning rate parameter for negative updates. </p>
<p>The learning parameter determines the speed at which the QFunction is modified with respect to new data, when updates are negative.</p>
<p>Note that this parameter can be zero.</p>
<p>The learning rate parameter must be &gt;= 0.0 and &lt;= 1.0, otherwise the function will throw an std::invalid_argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">b</td><td>The new learning rate parameter for negative updates. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa02544fb4e7edb44066eba3ae155fc46"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa02544fb4e7edb44066eba3ae155fc46">&#9670;&nbsp;</a></span>setPositiveLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::HystereticQLearning::setPositiveLearningRate </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>a</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the learning rate parameter for positive updates. </p>
<p>The learning parameter determines the speed at which the QFunction is modified with respect to new data, when updates are positive.</p>
<p>The learning rate parameter must be &gt; 0.0 and &lt;= 1.0, otherwise the function will throw an std::invalid_argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">a</td><td>The new learning rate parameter for positive updates. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a78dea7a0d6abd24f5d306a97c0f51599"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a78dea7a0d6abd24f5d306a97c0f51599">&#9670;&nbsp;</a></span>stepUpdateQ()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::HystereticQLearning::stepUpdateQ </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>rew</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function updates the internal QFunction using the discount set during construction. </p>
<p>This function takes a single experience point and uses it to update the QFunction. This is a very efficient method to keep the QFunction up to date with the latest experience.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The previous state. </td></tr>
    <tr><td class="paramname">a</td><td>The action performed. </td></tr>
    <tr><td class="paramname">s1</td><td>The new state. </td></tr>
    <tr><td class="paramname">rew</td><td>The reward obtained. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>include/AIToolbox/MDP/Algorithms/<a class="el" href="HystereticQLearning_8hpp_source.html">HystereticQLearning.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.17-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
</div>
</body>
</html>
