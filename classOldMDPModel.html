<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AIToolbox: OldMDPModel Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AIToolbox
   </div>
   <div id="projectbrief">A library that offers tools for AI problem solving.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classOldMDPModel.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#friends">Friends</a> &#124;
<a href="classOldMDPModel-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">OldMDPModel Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>This class represents a Markov Decision Process.  
 <a href="classOldMDPModel.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="OldMDPModel_8hpp_source.html">/home/svalorzen/Libraries/Self/AIToolbox/test/MDP/Utils/OldMDPModel.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:ae4249d1e30d70f5615c0fe787170da50"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#ae4249d1e30d70f5615c0fe787170da50">TransitionMatrix</a> = <a class="el" href="namespaceAIToolbox.html#aa09bff0da64cdd264561fe009fa85812">AIToolbox::DumbMatrix3D</a></td></tr>
<tr class="separator:ae4249d1e30d70f5615c0fe787170da50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67311240122128f91ee83b203b7e8f83"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a67311240122128f91ee83b203b7e8f83">RewardMatrix</a> = <a class="el" href="namespaceAIToolbox.html#aa09bff0da64cdd264561fe009fa85812">AIToolbox::DumbMatrix3D</a></td></tr>
<tr class="separator:a67311240122128f91ee83b203b7e8f83"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:aa62e2c03fdd0334a302cf3cc2014ceda"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#aa62e2c03fdd0334a302cf3cc2014ceda">OldMDPModel</a> (size_t s, size_t a, double discount=1.0)</td></tr>
<tr class="memdesc:aa62e2c03fdd0334a302cf3cc2014ceda"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic constructor.  <a href="classOldMDPModel.html#aa62e2c03fdd0334a302cf3cc2014ceda">More...</a><br /></td></tr>
<tr class="separator:aa62e2c03fdd0334a302cf3cc2014ceda"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa7cfcbab3d5cd16648d521b80e64b200"><td class="memTemplParams" colspan="2">template&lt;AIToolbox::IsNaive3DMatrix T, AIToolbox::IsNaive3DMatrix R&gt; </td></tr>
<tr class="memitem:aa7cfcbab3d5cd16648d521b80e64b200"><td class="memTemplItemLeft" align="right" valign="top">&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#aa7cfcbab3d5cd16648d521b80e64b200">OldMDPModel</a> (size_t s, size_t a, const T &amp;t, const R &amp;r, double d=1.0)</td></tr>
<tr class="memdesc:aa7cfcbab3d5cd16648d521b80e64b200"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic constructor.  <a href="classOldMDPModel.html#aa7cfcbab3d5cd16648d521b80e64b200">More...</a><br /></td></tr>
<tr class="separator:aa7cfcbab3d5cd16648d521b80e64b200"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23bad0e882bbcacfc5c988e1746b80db"><td class="memTemplParams" colspan="2">template&lt;AIToolbox::MDP::IsModel M&gt; </td></tr>
<tr class="memitem:a23bad0e882bbcacfc5c988e1746b80db"><td class="memTemplItemLeft" align="right" valign="top">&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a23bad0e882bbcacfc5c988e1746b80db">OldMDPModel</a> (const M &amp;model)</td></tr>
<tr class="memdesc:a23bad0e882bbcacfc5c988e1746b80db"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy constructor from any valid MDP model.  <a href="classOldMDPModel.html#a23bad0e882bbcacfc5c988e1746b80db">More...</a><br /></td></tr>
<tr class="separator:a23bad0e882bbcacfc5c988e1746b80db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02f8101611255bbcc26a419c29283d0e"><td class="memTemplParams" colspan="2">template&lt;AIToolbox::IsNaive3DMatrix T&gt; </td></tr>
<tr class="memitem:a02f8101611255bbcc26a419c29283d0e"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a02f8101611255bbcc26a419c29283d0e">setTransitionFunction</a> (const T &amp;t)</td></tr>
<tr class="memdesc:a02f8101611255bbcc26a419c29283d0e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function replaces the <a class="el" href="classOldMDPModel.html" title="This class represents a Markov Decision Process.">OldMDPModel</a> transition function with the one provided.  <a href="classOldMDPModel.html#a02f8101611255bbcc26a419c29283d0e">More...</a><br /></td></tr>
<tr class="separator:a02f8101611255bbcc26a419c29283d0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e8565ce6da2f01cb457d97bef6a9dff"><td class="memTemplParams" colspan="2">template&lt;AIToolbox::IsNaive3DMatrix R&gt; </td></tr>
<tr class="memitem:a8e8565ce6da2f01cb457d97bef6a9dff"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a8e8565ce6da2f01cb457d97bef6a9dff">setRewardFunction</a> (const R &amp;r)</td></tr>
<tr class="memdesc:a8e8565ce6da2f01cb457d97bef6a9dff"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function replaces the <a class="el" href="classOldMDPModel.html" title="This class represents a Markov Decision Process.">OldMDPModel</a> reward function with the one provided.  <a href="classOldMDPModel.html#a8e8565ce6da2f01cb457d97bef6a9dff">More...</a><br /></td></tr>
<tr class="separator:a8e8565ce6da2f01cb457d97bef6a9dff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0447e11e8015945ec46b76caa6fd960b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a0447e11e8015945ec46b76caa6fd960b">setDiscount</a> (double d)</td></tr>
<tr class="memdesc:a0447e11e8015945ec46b76caa6fd960b"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets a new discount factor for the <a class="el" href="classOldMDPModel.html" title="This class represents a Markov Decision Process.">OldMDPModel</a>.  <a href="classOldMDPModel.html#a0447e11e8015945ec46b76caa6fd960b">More...</a><br /></td></tr>
<tr class="separator:a0447e11e8015945ec46b76caa6fd960b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa869ce052f5f713803abc04b56c51387"><td class="memItemLeft" align="right" valign="top">std::tuple&lt; size_t, double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#aa869ce052f5f713803abc04b56c51387">sampleSR</a> (size_t s, size_t a) const</td></tr>
<tr class="memdesc:aa869ce052f5f713803abc04b56c51387"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function samples the MDP for the specified state action pair.  <a href="classOldMDPModel.html#aa869ce052f5f713803abc04b56c51387">More...</a><br /></td></tr>
<tr class="separator:aa869ce052f5f713803abc04b56c51387"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa621881470e4048f1afa7ec0a0f0754f"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#aa621881470e4048f1afa7ec0a0f0754f">getS</a> () const</td></tr>
<tr class="memdesc:aa621881470e4048f1afa7ec0a0f0754f"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of states of the world.  <a href="classOldMDPModel.html#aa621881470e4048f1afa7ec0a0f0754f">More...</a><br /></td></tr>
<tr class="separator:aa621881470e4048f1afa7ec0a0f0754f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f3266b48a2dab2ebc816b12217dc5a0"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a4f3266b48a2dab2ebc816b12217dc5a0">getA</a> () const</td></tr>
<tr class="memdesc:a4f3266b48a2dab2ebc816b12217dc5a0"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of available actions to the agent.  <a href="classOldMDPModel.html#a4f3266b48a2dab2ebc816b12217dc5a0">More...</a><br /></td></tr>
<tr class="separator:a4f3266b48a2dab2ebc816b12217dc5a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21273c8dd022590b352bbba8955ac6d3"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a21273c8dd022590b352bbba8955ac6d3">getDiscount</a> () const</td></tr>
<tr class="memdesc:a21273c8dd022590b352bbba8955ac6d3"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the currently set discount factor.  <a href="classOldMDPModel.html#a21273c8dd022590b352bbba8955ac6d3">More...</a><br /></td></tr>
<tr class="separator:a21273c8dd022590b352bbba8955ac6d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbc8688484752901f432b03f2e2e0604"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#acbc8688484752901f432b03f2e2e0604">getTransitionProbability</a> (size_t s, size_t a, size_t s1) const</td></tr>
<tr class="memdesc:acbc8688484752901f432b03f2e2e0604"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the stored transition probability for the specified transition.  <a href="classOldMDPModel.html#acbc8688484752901f432b03f2e2e0604">More...</a><br /></td></tr>
<tr class="separator:acbc8688484752901f432b03f2e2e0604"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa9f2b5caa82fd85edfedbdc98a5bc61"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#afa9f2b5caa82fd85edfedbdc98a5bc61">getExpectedReward</a> (size_t s, size_t a, size_t s1) const</td></tr>
<tr class="memdesc:afa9f2b5caa82fd85edfedbdc98a5bc61"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the stored expected reward for the specified transition.  <a href="classOldMDPModel.html#afa9f2b5caa82fd85edfedbdc98a5bc61">More...</a><br /></td></tr>
<tr class="separator:afa9f2b5caa82fd85edfedbdc98a5bc61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86be447802578829f44e3dbca05341dc"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classOldMDPModel.html#ae4249d1e30d70f5615c0fe787170da50">TransitionMatrix</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a86be447802578829f44e3dbca05341dc">getTransitionFunction</a> () const</td></tr>
<tr class="memdesc:a86be447802578829f44e3dbca05341dc"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the transition matrix for inspection.  <a href="classOldMDPModel.html#a86be447802578829f44e3dbca05341dc">More...</a><br /></td></tr>
<tr class="separator:a86be447802578829f44e3dbca05341dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fdba18eacac28e5c023a005e4bddcf4"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classOldMDPModel.html#a67311240122128f91ee83b203b7e8f83">RewardMatrix</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a0fdba18eacac28e5c023a005e4bddcf4">getRewardFunction</a> () const</td></tr>
<tr class="memdesc:a0fdba18eacac28e5c023a005e4bddcf4"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the rewards matrix for inspection.  <a href="classOldMDPModel.html#a0fdba18eacac28e5c023a005e4bddcf4">More...</a><br /></td></tr>
<tr class="separator:a0fdba18eacac28e5c023a005e4bddcf4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c5f0b6bf5f51be457401483776c2d07"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a8c5f0b6bf5f51be457401483776c2d07">isTerminal</a> (size_t s) const</td></tr>
<tr class="memdesc:a8c5f0b6bf5f51be457401483776c2d07"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns whether a given state is a terminal.  <a href="classOldMDPModel.html#a8c5f0b6bf5f51be457401483776c2d07">More...</a><br /></td></tr>
<tr class="separator:a8c5f0b6bf5f51be457401483776c2d07"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="friends"></a>
Friends</h2></td></tr>
<tr class="memitem:a92b1edb202594eb08a1278f42a0eefd2"><td class="memItemLeft" align="right" valign="top">std::istream &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classOldMDPModel.html#a92b1edb202594eb08a1278f42a0eefd2">operator&gt;&gt;</a> (std::istream &amp;is, <a class="el" href="classOldMDPModel.html">OldMDPModel</a> &amp;)</td></tr>
<tr class="separator:a92b1edb202594eb08a1278f42a0eefd2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This class represents a Markov Decision Process. </p>
<p>This is the old class representing a Model in the <a class="el" href="namespaceAIToolbox.html">AIToolbox</a> library. It was discontinued since it does not use <a class="el" href="namespaceEigen.html">Eigen</a> internally, which makes it slower. We can still use it to test codepaths which do not rely on <a class="el" href="namespaceEigen.html">Eigen</a> though.</p>
<p>A Markov Decision Process (MDP) is a way to model decision making. The idea is that there is an agent situated in a stochastic environment which changes in discrete "timesteps". The agent can influence the way the environment changes via "actions". For each action the agent can perform, the environment will transition from a state "s" to a state "s1" following a certain transition function. The transition function specifies, for each triple SxAxS' the probability that such a transition will happen.</p>
<p>In addition, associated with transitions, the agent is able to obtain rewards. Thus, if it does good, the agent will obtain a higher reward than if it performed badly. The reward obtained by the agent is in addition associated with a "discount" factor: at every step, the possible reward that the agent can collect is multiplied by this factor, which is a number between 0 and 1. The discount factor is used to model the fact that often it is preferable to obtain something sooner, rather than later.</p>
<p>Since all of this is governed by probabilities, it is possible to solve an MDP model in order to obtain an "optimal policy", which is a way to select an action from a state which will maximize the expected reward that the agent is going to collect during its life. The expected reward is computed as the sum of every reward the agent collects at every timestep, keeping in mind that at every timestep the reward is further and further discounted.</p>
<p>Solving an MDP in such a way is called "planning". Planning solutions often include an "horizon", which is the number of timesteps that are included in an episode. They can be finite or infinite. The optimal policy changes with respect to the horizon, since a higher horizon may offer access to reward-gaining opportunities farther in the future.</p>
<p>An MDP policy (be it the optimal one or another), is associated with two functions: a ValueFunction and a QFunction. The ValueFunction represents the expected return for the agent from any initial state, given that actions are going to be selected according to the policy. The QFunction is similar: it gives the expected return for a specific state-action pair, given that after the specified action one will act according to the policy.</p>
<p>Given that we are usually interested about the optimal policy, there are a couple of properties that are associated with the optimal policies functions. First, the optimal policy can be derived from the optimal QFunction. The optimal policy simply selects, in a given state "s", the action that maximizes the value of the QFunction. In the same way, the optimal ValueFunction can be computed from the optimal QFunction by selecting the max with respect to the action.</p>
<p>Since so much information can be extracted from the QFunction, lots of methods (mostly in Reinforcement Learning) try to learn it. </p>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="a67311240122128f91ee83b203b7e8f83"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67311240122128f91ee83b203b7e8f83">&#9670;&nbsp;</a></span>RewardMatrix</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classOldMDPModel.html#a67311240122128f91ee83b203b7e8f83">OldMDPModel::RewardMatrix</a> =  <a class="el" href="namespaceAIToolbox.html#aa09bff0da64cdd264561fe009fa85812">AIToolbox::DumbMatrix3D</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae4249d1e30d70f5615c0fe787170da50"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4249d1e30d70f5615c0fe787170da50">&#9670;&nbsp;</a></span>TransitionMatrix</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classOldMDPModel.html#ae4249d1e30d70f5615c0fe787170da50">OldMDPModel::TransitionMatrix</a> =  <a class="el" href="namespaceAIToolbox.html#aa09bff0da64cdd264561fe009fa85812">AIToolbox::DumbMatrix3D</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="aa62e2c03fdd0334a302cf3cc2014ceda"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa62e2c03fdd0334a302cf3cc2014ceda">&#9670;&nbsp;</a></span>OldMDPModel() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">OldMDPModel::OldMDPModel </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>discount</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic constructor. </p>
<p>This constructor initializes the <a class="el" href="classOldMDPModel.html" title="This class represents a Markov Decision Process.">OldMDPModel</a> so that all transitions happen with probability 0 but for transitions that bring back to the same state, no matter the action.</p>
<p>All rewards are set to 0. The discount parameter is set to 1.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The number of states of the world. </td></tr>
    <tr><td class="paramname">a</td><td>The number of actions available to the agent. </td></tr>
    <tr><td class="paramname">discount</td><td>The discount factor for the MDP. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa7cfcbab3d5cd16648d521b80e64b200"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa7cfcbab3d5cd16648d521b80e64b200">&#9670;&nbsp;</a></span>OldMDPModel() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;AIToolbox::IsNaive3DMatrix T, AIToolbox::IsNaive3DMatrix R&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">OldMDPModel::OldMDPModel </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const R &amp;&#160;</td>
          <td class="paramname"><em>r</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>d</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic constructor. </p>
<p>This constructor takes two arbitrary three dimensional containers and tries to copy their contents into the transitions and rewards matrices respectively.</p>
<p>The containers need to support data access through operator[]. In addition, the dimensions of the containers must match the ones provided as arguments (for three dimensions: s,a,s).</p>
<p>This is important, as this constructor DOES NOT perform any size checks on the external containers.</p>
<p>Internal values of the containers will be converted to double, so these conversions must be possible.</p>
<p>In addition, the transition container must contain a valid transition function.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="namespaceAIToolbox.html#a2ef6c271697802b01b05562715052bf4" title="Copies a 3d container into another 3d container.">copyDumb3D()</a></dd></dl>
<p>The discount parameter must be between 0 and 1 included, otherwise the constructor will throw an std::invalid_argument.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The external transition container type. </td></tr>
    <tr><td class="paramname">R</td><td>The external rewards container type. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The number of states of the world. </td></tr>
    <tr><td class="paramname">a</td><td>The number of actions available to the agent. </td></tr>
    <tr><td class="paramname">t</td><td>The external transitions container. </td></tr>
    <tr><td class="paramname">r</td><td>The external rewards container. </td></tr>
    <tr><td class="paramname">d</td><td>The discount factor for the MDP. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a23bad0e882bbcacfc5c988e1746b80db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23bad0e882bbcacfc5c988e1746b80db">&#9670;&nbsp;</a></span>OldMDPModel() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;AIToolbox::MDP::IsModel M&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">OldMDPModel::OldMDPModel </td>
          <td>(</td>
          <td class="paramtype">const M &amp;&#160;</td>
          <td class="paramname"><em>model</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Copy constructor from any valid MDP model. </p>
<p>This allows to copy from any other model. A nice use for this is to convert any model which computes probabilities on the fly into an <a class="el" href="classOldMDPModel.html" title="This class represents a Markov Decision Process.">OldMDPModel</a> where probabilities are all stored for fast access. Of course such a solution can be done only when the number of states and actions is not too big.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">M</td><td>The type of the other model. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The model that needs to be copied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a4f3266b48a2dab2ebc816b12217dc5a0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f3266b48a2dab2ebc816b12217dc5a0">&#9670;&nbsp;</a></span>getA()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t OldMDPModel::getA </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the number of available actions to the agent. </p>
<dl class="section return"><dt>Returns</dt><dd>The total number of actions. </dd></dl>

</div>
</div>
<a id="a21273c8dd022590b352bbba8955ac6d3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a21273c8dd022590b352bbba8955ac6d3">&#9670;&nbsp;</a></span>getDiscount()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double OldMDPModel::getDiscount </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the currently set discount factor. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set discount factor. </dd></dl>

</div>
</div>
<a id="afa9f2b5caa82fd85edfedbdc98a5bc61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afa9f2b5caa82fd85edfedbdc98a5bc61">&#9670;&nbsp;</a></span>getExpectedReward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double OldMDPModel::getExpectedReward </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the stored expected reward for the specified transition. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The initial state of the transition. </td></tr>
    <tr><td class="paramname">a</td><td>The action performed in the transition. </td></tr>
    <tr><td class="paramname">s1</td><td>The final state of the transition.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The expected reward of the specified transition. </dd></dl>

</div>
</div>
<a id="a0fdba18eacac28e5c023a005e4bddcf4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0fdba18eacac28e5c023a005e4bddcf4">&#9670;&nbsp;</a></span>getRewardFunction()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classOldMDPModel.html#a67311240122128f91ee83b203b7e8f83">OldMDPModel::RewardMatrix</a> &amp; OldMDPModel::getRewardFunction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the rewards matrix for inspection. </p>
<dl class="section return"><dt>Returns</dt><dd>The rewards matrix. </dd></dl>

</div>
</div>
<a id="aa621881470e4048f1afa7ec0a0f0754f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa621881470e4048f1afa7ec0a0f0754f">&#9670;&nbsp;</a></span>getS()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t OldMDPModel::getS </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the number of states of the world. </p>
<dl class="section return"><dt>Returns</dt><dd>The total number of states. </dd></dl>

</div>
</div>
<a id="a86be447802578829f44e3dbca05341dc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a86be447802578829f44e3dbca05341dc">&#9670;&nbsp;</a></span>getTransitionFunction()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classOldMDPModel.html#ae4249d1e30d70f5615c0fe787170da50">OldMDPModel::TransitionMatrix</a> &amp; OldMDPModel::getTransitionFunction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the transition matrix for inspection. </p>
<dl class="section return"><dt>Returns</dt><dd>The transition matrix. </dd></dl>

</div>
</div>
<a id="acbc8688484752901f432b03f2e2e0604"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acbc8688484752901f432b03f2e2e0604">&#9670;&nbsp;</a></span>getTransitionProbability()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double OldMDPModel::getTransitionProbability </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns the stored transition probability for the specified transition. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The initial state of the transition. </td></tr>
    <tr><td class="paramname">a</td><td>The action performed in the transition. </td></tr>
    <tr><td class="paramname">s1</td><td>The final state of the transition.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The probability of the specified transition. </dd></dl>

</div>
</div>
<a id="a8c5f0b6bf5f51be457401483776c2d07"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8c5f0b6bf5f51be457401483776c2d07">&#9670;&nbsp;</a></span>isTerminal()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool OldMDPModel::isTerminal </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function returns whether a given state is a terminal. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The state examined.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>True if the input state is a terminal, false otherwise. </dd></dl>

</div>
</div>
<a id="aa869ce052f5f713803abc04b56c51387"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa869ce052f5f713803abc04b56c51387">&#9670;&nbsp;</a></span>sampleSR()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; size_t, double &gt; OldMDPModel::sampleSR </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>a</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function samples the MDP for the specified state action pair. </p>
<p>This function samples the model for simulated experience. The transition and reward functions are used to produce, from the state action pair inserted as arguments, a possible new state with respective reward. The new state is picked from all possible states that the MDP allows transitioning to, each with probability equal to the same probability of the transition in the model. After a new state is picked, the reward is the corresponding reward contained in the reward function.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The state that needs to be sampled. </td></tr>
    <tr><td class="paramname">a</td><td>The action that needs to be sampled.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A tuple containing a new state and a reward. </dd></dl>

</div>
</div>
<a id="a0447e11e8015945ec46b76caa6fd960b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0447e11e8015945ec46b76caa6fd960b">&#9670;&nbsp;</a></span>setDiscount()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void OldMDPModel::setDiscount </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>d</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>This function sets a new discount factor for the <a class="el" href="classOldMDPModel.html" title="This class represents a Markov Decision Process.">OldMDPModel</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">d</td><td>The new discount factor for the <a class="el" href="classOldMDPModel.html" title="This class represents a Markov Decision Process.">OldMDPModel</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a8e8565ce6da2f01cb457d97bef6a9dff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e8565ce6da2f01cb457d97bef6a9dff">&#9670;&nbsp;</a></span>setRewardFunction()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;AIToolbox::IsNaive3DMatrix R&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void OldMDPModel::setRewardFunction </td>
          <td>(</td>
          <td class="paramtype">const R &amp;&#160;</td>
          <td class="paramname"><em>r</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function replaces the <a class="el" href="classOldMDPModel.html" title="This class represents a Markov Decision Process.">OldMDPModel</a> reward function with the one provided. </p>
<p>The container needs to support data access through operator[]. In addition, the dimensions of the containers must match the ones provided as arguments (for three dimensions: s,a,s).</p>
<p>This is important, as this constructor DOES NOT perform any size checks on the external containers.</p>
<p>Internal values of the container will be converted to double, so these conversions must be possible.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">R</td><td>The external rewards container type. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">r</td><td>The external rewards container. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a02f8101611255bbcc26a419c29283d0e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02f8101611255bbcc26a419c29283d0e">&#9670;&nbsp;</a></span>setTransitionFunction()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;AIToolbox::IsNaive3DMatrix T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void OldMDPModel::setTransitionFunction </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>t</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function replaces the <a class="el" href="classOldMDPModel.html" title="This class represents a Markov Decision Process.">OldMDPModel</a> transition function with the one provided. </p>
<p>This function will throw a std::invalid_argument if the matrix provided does not respect the constraints specified in the mdpCheck() function.</p>
<p>The container needs to support data access through operator[]. In addition, the dimensions of the container must match the ones provided as arguments (for three dimensions: s,a,s).</p>
<p>This is important, as this constructor DOES NOT perform any size checks on the external container.</p>
<p>Internal values of the container will be converted to double, so these conversions must be possible.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The external transition container type. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">t</td><td>The external transitions container. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Friends And Related Function Documentation</h2>
<a id="a92b1edb202594eb08a1278f42a0eefd2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a92b1edb202594eb08a1278f42a0eefd2">&#9670;&nbsp;</a></span>operator&gt;&gt;</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::istream&amp; operator&gt;&gt; </td>
          <td>(</td>
          <td class="paramtype">std::istream &amp;&#160;</td>
          <td class="paramname"><em>is</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classOldMDPModel.html">OldMDPModel</a> &amp;&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>test/MDP/Utils/<a class="el" href="OldMDPModel_8hpp_source.html">OldMDPModel.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.17-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
</div>
</body>
</html>
