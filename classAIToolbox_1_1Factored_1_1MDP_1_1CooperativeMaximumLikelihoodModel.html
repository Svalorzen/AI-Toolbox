<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AIToolbox: AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AIToolbox
   </div>
   <div id="projectbrief">A library that offers tools for AI problem solving.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>This class models <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> as a <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeModel.html" title="This class models a cooperative MDP. ">CooperativeModel</a> using Maximum Likelihood.  
 <a href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="CooperativeMaximumLikelihoodModel_8hpp_source.html">CooperativeMaximumLikelihoodModel.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:aba1e7d91d0dcb6898d5bb8266044d5b8"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#aba1e7d91d0dcb6898d5bb8266044d5b8">TransitionMatrix</a> = <a class="el" href="namespaceAIToolbox_1_1Factored.html#ae982f64154558584f55a5f119e6a155c">DDN</a></td></tr>
<tr class="separator:aba1e7d91d0dcb6898d5bb8266044d5b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38f986868e6b3586ed063e06b869902c"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a38f986868e6b3586ed063e06b869902c">RewardMatrix</a> = std::vector&lt; <a class="el" href="namespaceAIToolbox.html#a1e6976de7a0159cd1630c4f2553fc9f3">Vector</a> &gt;</td></tr>
<tr class="separator:a38f986868e6b3586ed063e06b869902c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a60faa98b1c1f03b8c6a37d8b4a0a80d0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a60faa98b1c1f03b8c6a37d8b4a0a80d0">CooperativeMaximumLikelihoodModel</a> (const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html">CooperativeExperience</a> &amp;exp, double discount=1.0, bool <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#ae40bd14174897a23f17c2081529512a8">sync</a>=false)</td></tr>
<tr class="memdesc:a60faa98b1c1f03b8c6a37d8b4a0a80d0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor using previous Experience.  <a href="#a60faa98b1c1f03b8c6a37d8b4a0a80d0">More...</a><br /></td></tr>
<tr class="separator:a60faa98b1c1f03b8c6a37d8b4a0a80d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae40bd14174897a23f17c2081529512a8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#ae40bd14174897a23f17c2081529512a8">sync</a> ()</td></tr>
<tr class="memdesc:ae40bd14174897a23f17c2081529512a8"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function syncs the whole <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html" title="This class models CooperativeExperience as a CooperativeModel using Maximum Likelihood. ">CooperativeMaximumLikelihoodModel</a> to the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>.  <a href="#ae40bd14174897a23f17c2081529512a8">More...</a><br /></td></tr>
<tr class="separator:ae40bd14174897a23f17c2081529512a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bc790743b6d18d11c60e9cbfdd6a501"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a5bc790743b6d18d11c60e9cbfdd6a501">sync</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a)</td></tr>
<tr class="memdesc:a5bc790743b6d18d11c60e9cbfdd6a501"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function syncs a state-action pair to the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>.  <a href="#a5bc790743b6d18d11c60e9cbfdd6a501">More...</a><br /></td></tr>
<tr class="separator:a5bc790743b6d18d11c60e9cbfdd6a501"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1893bdb7c85e4ba25c61a6c60f69e5d3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a1893bdb7c85e4ba25c61a6c60f69e5d3">sync</a> (const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html#a3a3dcdccdf42909e7d7329bcf10285f6">CooperativeExperience::Indeces</a> &amp;indeces)</td></tr>
<tr class="memdesc:a1893bdb7c85e4ba25c61a6c60f69e5d3"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function syncs the given indeces to the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>.  <a href="#a1893bdb7c85e4ba25c61a6c60f69e5d3">More...</a><br /></td></tr>
<tr class="separator:a1893bdb7c85e4ba25c61a6c60f69e5d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b1432a1636ca9fd3af58e5824645315"><td class="memItemLeft" align="right" valign="top">std::tuple&lt; <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a>, double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a1b1432a1636ca9fd3af58e5824645315">sampleSR</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a) const</td></tr>
<tr class="memdesc:a1b1432a1636ca9fd3af58e5824645315"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function samples the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> with the specified state action pair.  <a href="#a1b1432a1636ca9fd3af58e5824645315">More...</a><br /></td></tr>
<tr class="separator:a1b1432a1636ca9fd3af58e5824645315"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a571784c02ed74a10e92f7f86f62a0a3b"><td class="memItemLeft" align="right" valign="top">std::tuple&lt; <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a>, <a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a571784c02ed74a10e92f7f86f62a0a3b">sampleSRs</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a) const</td></tr>
<tr class="memdesc:a571784c02ed74a10e92f7f86f62a0a3b"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function samples the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> with the specified state action pair.  <a href="#a571784c02ed74a10e92f7f86f62a0a3b">More...</a><br /></td></tr>
<tr class="separator:a571784c02ed74a10e92f7f86f62a0a3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd8b9e61d51d4740c2d75702a7a8e060"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#afd8b9e61d51d4740c2d75702a7a8e060">sampleSR</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a, <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> *s1) const</td></tr>
<tr class="memdesc:afd8b9e61d51d4740c2d75702a7a8e060"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function samples the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> with the specified state action pair.  <a href="#afd8b9e61d51d4740c2d75702a7a8e060">More...</a><br /></td></tr>
<tr class="separator:afd8b9e61d51d4740c2d75702a7a8e060"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8e0473a7b2bb23c631027b3dc8d4b78"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#af8e0473a7b2bb23c631027b3dc8d4b78">sampleSRs</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a, <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> *s1, <a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a> *rews) const</td></tr>
<tr class="memdesc:af8e0473a7b2bb23c631027b3dc8d4b78"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function samples the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> with the specified state action pair.  <a href="#af8e0473a7b2bb23c631027b3dc8d4b78">More...</a><br /></td></tr>
<tr class="separator:af8e0473a7b2bb23c631027b3dc8d4b78"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a973f4656dda34bb919d974e97ed8edce"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a973f4656dda34bb919d974e97ed8edce">getTransitionProbability</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s1) const</td></tr>
<tr class="memdesc:a973f4656dda34bb919d974e97ed8edce"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the stored transition probability for the specified transition.  <a href="#a973f4656dda34bb919d974e97ed8edce">More...</a><br /></td></tr>
<tr class="separator:a973f4656dda34bb919d974e97ed8edce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c1586a6faa2f3505fd69827c75dbdb9"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a4c1586a6faa2f3505fd69827c75dbdb9">getExpectedReward</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s1) const</td></tr>
<tr class="memdesc:a4c1586a6faa2f3505fd69827c75dbdb9"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the stored expected reward for the specified transition.  <a href="#a4c1586a6faa2f3505fd69827c75dbdb9">More...</a><br /></td></tr>
<tr class="separator:a4c1586a6faa2f3505fd69827c75dbdb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89e87be497ca46ad06230a5ba095c708"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a89e87be497ca46ad06230a5ba095c708">getExpectedRewards</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s1) const</td></tr>
<tr class="memdesc:a89e87be497ca46ad06230a5ba095c708"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the stored expected rewards for the specified transition.  <a href="#a89e87be497ca46ad06230a5ba095c708">More...</a><br /></td></tr>
<tr class="separator:a89e87be497ca46ad06230a5ba095c708"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82d8716ca6161d0fdc140c05471f263a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a82d8716ca6161d0fdc140c05471f263a">getExpectedRewards</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;s1, <a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a> *rews) const</td></tr>
<tr class="memdesc:a82d8716ca6161d0fdc140c05471f263a"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the stored expected rewards for the specified transition.  <a href="#a82d8716ca6161d0fdc140c05471f263a">More...</a><br /></td></tr>
<tr class="separator:a82d8716ca6161d0fdc140c05471f263a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abbd723ac7ceb74d8d5b25d4035152623"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#abbd723ac7ceb74d8d5b25d4035152623">getS</a> () const</td></tr>
<tr class="memdesc:abbd723ac7ceb74d8d5b25d4035152623"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of states of the world.  <a href="#abbd723ac7ceb74d8d5b25d4035152623">More...</a><br /></td></tr>
<tr class="separator:abbd723ac7ceb74d8d5b25d4035152623"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8adaa44d9ac8e4031cc553aa7c00665d"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a8adaa44d9ac8e4031cc553aa7c00665d">getA</a> () const</td></tr>
<tr class="memdesc:a8adaa44d9ac8e4031cc553aa7c00665d"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of available actions to the agent.  <a href="#a8adaa44d9ac8e4031cc553aa7c00665d">More...</a><br /></td></tr>
<tr class="separator:a8adaa44d9ac8e4031cc553aa7c00665d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad74d3c92a0b513b6690232176bacfdb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#aad74d3c92a0b513b6690232176bacfdb">setDiscount</a> (double d)</td></tr>
<tr class="memdesc:aad74d3c92a0b513b6690232176bacfdb"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets a new discount factor for the Model.  <a href="#aad74d3c92a0b513b6690232176bacfdb">More...</a><br /></td></tr>
<tr class="separator:aad74d3c92a0b513b6690232176bacfdb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a984340b792aeeb7179eb2a7b94359abb"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a984340b792aeeb7179eb2a7b94359abb">getDiscount</a> () const</td></tr>
<tr class="memdesc:a984340b792aeeb7179eb2a7b94359abb"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the currently set discount factor.  <a href="#a984340b792aeeb7179eb2a7b94359abb">More...</a><br /></td></tr>
<tr class="separator:a984340b792aeeb7179eb2a7b94359abb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49dd43740024f119ff7060b83d49ab20"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html">CooperativeExperience</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a49dd43740024f119ff7060b83d49ab20">getExperience</a> () const</td></tr>
<tr class="memdesc:a49dd43740024f119ff7060b83d49ab20"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function enables inspection of the underlying Experience of the RLModel.  <a href="#a49dd43740024f119ff7060b83d49ab20">More...</a><br /></td></tr>
<tr class="separator:a49dd43740024f119ff7060b83d49ab20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad96a37614fdc22cf42cff2612e30c056"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#aba1e7d91d0dcb6898d5bb8266044d5b8">TransitionMatrix</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#ad96a37614fdc22cf42cff2612e30c056">getTransitionFunction</a> () const</td></tr>
<tr class="memdesc:ad96a37614fdc22cf42cff2612e30c056"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the transition matrix for inspection.  <a href="#ad96a37614fdc22cf42cff2612e30c056">More...</a><br /></td></tr>
<tr class="separator:ad96a37614fdc22cf42cff2612e30c056"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5cebb6e7445ca170cf3c32bc700e439d"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a38f986868e6b3586ed063e06b869902c">RewardMatrix</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a5cebb6e7445ca170cf3c32bc700e439d">getRewardFunction</a> () const</td></tr>
<tr class="memdesc:a5cebb6e7445ca170cf3c32bc700e439d"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the rewards matrix for inspection.  <a href="#a5cebb6e7445ca170cf3c32bc700e439d">More...</a><br /></td></tr>
<tr class="separator:a5cebb6e7445ca170cf3c32bc700e439d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97da0e173417f85154d25e750f99fd5e"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#af81c44d64cf98377be56973db15d0ede">DDNGraph</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a97da0e173417f85154d25e750f99fd5e">getGraph</a> () const</td></tr>
<tr class="memdesc:a97da0e173417f85154d25e750f99fd5e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the underlying DDNGraph of the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>.  <a href="#a97da0e173417f85154d25e750f99fd5e">More...</a><br /></td></tr>
<tr class="separator:a97da0e173417f85154d25e750f99fd5e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This class models <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> as a <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeModel.html" title="This class models a cooperative MDP. ">CooperativeModel</a> using Maximum Likelihood. </p>
<p>Often an <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> is not known in advance. It is known that it can assume a certain set of states, and that a certain set of actions are available to the agent, but not much more. Thus, in these cases, the goal is not only to find out the best policy for the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> we have, but at the same time learn the actual transition and reward functions of such a model. This task is called "reinforcement
learning".</p>
<p>This class helps with this. A naive approach in reinforcement learning is to keep track, for each action, of its results, and deduce transition probabilities and rewards based on the data collected in such a way. This class does just this, using Maximum Likelihood Estimates to decide what the transition probabilities and rewards are.</p>
<p>This class maps a <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> object to the most likely transition reward functions that produced it. The transition function is guaranteed to be a correct probability function, as in the sum of the probabilities of all transitions from a particular state and a particular action is always 1. Each instance is not directly synced with the supplied <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> object. This is to avoid possible overheads, as the user can optimize better depending on their use case. See <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#ae40bd14174897a23f17c2081529512a8" title="This function syncs the whole CooperativeMaximumLikelihoodModel to the underlying CooperativeExperien...">sync()</a>.</p>
<p>When little data is available, the deduced transition and reward functions may be significantly subject to noise. A possible way to improve on this is to artificially bias the data as to skew it towards certain distributions. This could be done if some knowledge of the model (even approximate) is known, in order to speed up the learning process. Another way is to assume that all transitions are possible, add data to support that claim, and simply wait until the averages converge to the true values. Another thing that can be done is to associate with each fake datapoint an high reward: this will skew the agent into trying out new actions, thinking it will obtained the high rewards. This is able to obtain automatically a good degree of exploration in the early stages of an episode. Such a technique is called "optimistic
initialization".</p>
<p>Whether any of these techniques work or not can definitely depend on the model you are trying to approximate. Trying out things is good! </p>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="a38f986868e6b3586ed063e06b869902c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38f986868e6b3586ed063e06b869902c">&#9670;&nbsp;</a></span>RewardMatrix</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a38f986868e6b3586ed063e06b869902c">AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::RewardMatrix</a> =  std::vector&lt;<a class="el" href="namespaceAIToolbox.html#a1e6976de7a0159cd1630c4f2553fc9f3">Vector</a>&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aba1e7d91d0dcb6898d5bb8266044d5b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba1e7d91d0dcb6898d5bb8266044d5b8">&#9670;&nbsp;</a></span>TransitionMatrix</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#aba1e7d91d0dcb6898d5bb8266044d5b8">AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::TransitionMatrix</a> =  <a class="el" href="namespaceAIToolbox_1_1Factored.html#ae982f64154558584f55a5f119e6a155c">DDN</a></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a60faa98b1c1f03b8c6a37d8b4a0a80d0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a60faa98b1c1f03b8c6a37d8b4a0a80d0">&#9670;&nbsp;</a></span>CooperativeMaximumLikelihoodModel()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::CooperativeMaximumLikelihoodModel </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html">CooperativeExperience</a> &amp;&#160;</td>
          <td class="paramname"><em>exp</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>discount</em> = <code>1.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>sync</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor using previous Experience. </p>
<p>This constructor stores a reference to the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> that will be used to learn an <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> Model from the data, and initializes internal Model data.</p>
<p>The user can choose whether he wants to directly sync the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html" title="This class models CooperativeExperience as a CooperativeModel using Maximum Likelihood. ">CooperativeMaximumLikelihoodModel</a> to the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>, or delay it for later.</p>
<p>In the latter case the default transition function defines a transition of probability 1 for each state factor to 0, no matter the action or its parents.</p>
<p>In general it would be better to add some amount of bias to the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> so that when a new state-action pair is tried, the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html" title="This class models CooperativeExperience as a CooperativeModel using Maximum Likelihood. ">CooperativeMaximumLikelihoodModel</a> doesn't automatically compute 100% probability of transitioning to the resulting state, but smooths into it. This may depend on your problem though.</p>
<p>The default reward function is 0.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">exp</td><td>The <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> of the model. </td></tr>
    <tr><td class="paramname">discount</td><td>The discount used in solving methods. </td></tr>
    <tr><td class="paramname">sync</td><td>Whether to sync with the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> immediately or delay it. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a8adaa44d9ac8e4031cc553aa7c00665d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8adaa44d9ac8e4031cc553aa7c00665d">&#9670;&nbsp;</a></span>getA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a>&amp; AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getA </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the number of available actions to the agent. </p>
<dl class="section return"><dt>Returns</dt><dd>The total number of actions. </dd></dl>

</div>
</div>
<a id="a984340b792aeeb7179eb2a7b94359abb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a984340b792aeeb7179eb2a7b94359abb">&#9670;&nbsp;</a></span>getDiscount()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getDiscount </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the currently set discount factor. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set discount factor. </dd></dl>

</div>
</div>
<a id="a4c1586a6faa2f3505fd69827c75dbdb9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c1586a6faa2f3505fd69827c75dbdb9">&#9670;&nbsp;</a></span>getExpectedReward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getExpectedReward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the stored expected reward for the specified transition. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The initial state of the transition. </td></tr>
    <tr><td class="paramname">a</td><td>The action performed in the transition. </td></tr>
    <tr><td class="paramname">s1</td><td>The final state of the transition.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The expected reward of the specified transition. </dd></dl>

</div>
</div>
<a id="a89e87be497ca46ad06230a5ba095c708"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a89e87be497ca46ad06230a5ba095c708">&#9670;&nbsp;</a></span>getExpectedRewards() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a> AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getExpectedRewards </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the stored expected rewards for the specified transition. </p>
<p>This function returns a vector of the size of the state-space. The sum of the vector is the same as the value returned by the getExpectedReward(const State &amp;, const Action &amp;, const State &amp;) function.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The initial state of the transition. </td></tr>
    <tr><td class="paramname">a</td><td>The action performed in the transition. </td></tr>
    <tr><td class="paramname">s1</td><td>The final state of the transition.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The expected reward of the specified transition. </dd></dl>

</div>
</div>
<a id="a82d8716ca6161d0fdc140c05471f263a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82d8716ca6161d0fdc140c05471f263a">&#9670;&nbsp;</a></span>getExpectedRewards() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getExpectedRewards </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a> *&#160;</td>
          <td class="paramname"><em>rews</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the stored expected rewards for the specified transition. </p>
<p>This function is equivalent to getExpectedReward(const State &amp;, const Action &amp;, const State &amp;).</p>
<p>The only difference is that it allows to output the new Rewards into a pre-allocated Rewards, avoiding the need for an allocation at every sample.</p>
<p>NO CHECKS for nullptr are done.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The initial state of the transition. </td></tr>
    <tr><td class="paramname">a</td><td>The action performed in the transition. </td></tr>
    <tr><td class="paramname">s1</td><td>The final state of the transition.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The expected reward of the specified transition. </dd></dl>

</div>
</div>
<a id="a49dd43740024f119ff7060b83d49ab20"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a49dd43740024f119ff7060b83d49ab20">&#9670;&nbsp;</a></span>getExperience()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html">CooperativeExperience</a>&amp; AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getExperience </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function enables inspection of the underlying Experience of the RLModel. </p>
<dl class="section return"><dt>Returns</dt><dd>The underlying Experience of the RLModel. </dd></dl>

</div>
</div>
<a id="a97da0e173417f85154d25e750f99fd5e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a97da0e173417f85154d25e750f99fd5e">&#9670;&nbsp;</a></span>getGraph()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#af81c44d64cf98377be56973db15d0ede">DDNGraph</a>&amp; AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getGraph </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the underlying DDNGraph of the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>The underlying DDNGraph. </dd></dl>

</div>
</div>
<a id="a5cebb6e7445ca170cf3c32bc700e439d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5cebb6e7445ca170cf3c32bc700e439d">&#9670;&nbsp;</a></span>getRewardFunction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#a38f986868e6b3586ed063e06b869902c">RewardMatrix</a>&amp; AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getRewardFunction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the rewards matrix for inspection. </p>
<dl class="section return"><dt>Returns</dt><dd>The rewards matrix. </dd></dl>

</div>
</div>
<a id="abbd723ac7ceb74d8d5b25d4035152623"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abbd723ac7ceb74d8d5b25d4035152623">&#9670;&nbsp;</a></span>getS()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a>&amp; AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getS </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the number of states of the world. </p>
<dl class="section return"><dt>Returns</dt><dd>The total number of states. </dd></dl>

</div>
</div>
<a id="ad96a37614fdc22cf42cff2612e30c056"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad96a37614fdc22cf42cff2612e30c056">&#9670;&nbsp;</a></span>getTransitionFunction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html#aba1e7d91d0dcb6898d5bb8266044d5b8">TransitionMatrix</a>&amp; AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getTransitionFunction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the transition matrix for inspection. </p>
<dl class="section return"><dt>Returns</dt><dd>The transition matrix. </dd></dl>

</div>
</div>
<a id="a973f4656dda34bb919d974e97ed8edce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a973f4656dda34bb919d974e97ed8edce">&#9670;&nbsp;</a></span>getTransitionProbability()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::getTransitionProbability </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the stored transition probability for the specified transition. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The initial state of the transition. </td></tr>
    <tr><td class="paramname">a</td><td>The action performed in the transition. </td></tr>
    <tr><td class="paramname">s1</td><td>The final state of the transition.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The probability of the specified transition. </dd></dl>

</div>
</div>
<a id="a1b1432a1636ca9fd3af58e5824645315"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1b1432a1636ca9fd3af58e5824645315">&#9670;&nbsp;</a></span>sampleSR() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt;<a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a>, double&gt; AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::sampleSR </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function samples the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> with the specified state action pair. </p>
<p>This function samples the model for simulate experience. The transition and reward functions are used to produce, from the state action pair inserted as arguments, a possible new state with respective reward. The new state is picked from all possible states that the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> allows transitioning to, each with probability equal to the same probability of the transition in the model. After a new state is picked, the reward is the corresponding reward contained in the reward function.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The state that needs to be sampled. </td></tr>
    <tr><td class="paramname">a</td><td>The action that needs to be sampled.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A tuple containing a new state and a reward. </dd></dl>

</div>
</div>
<a id="afd8b9e61d51d4740c2d75702a7a8e060"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd8b9e61d51d4740c2d75702a7a8e060">&#9670;&nbsp;</a></span>sampleSR() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::sampleSR </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> *&#160;</td>
          <td class="paramname"><em>s1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function samples the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> with the specified state action pair. </p>
<p>This function is equivalent to sampleSR(const State &amp;, const Action &amp;).</p>
<p>The only difference is that it allows to output the new State into a pre-allocated State, avoiding the need for an allocation at every sample.</p>
<p>NO CHECKS for nullptr are done.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The state that needs to be sampled. </td></tr>
    <tr><td class="paramname">a</td><td>The action that needs to be sampled. </td></tr>
    <tr><td class="paramname">s1</td><td>The new state.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The reward for the sampled transition. </dd></dl>

</div>
</div>
<a id="a571784c02ed74a10e92f7f86f62a0a3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a571784c02ed74a10e92f7f86f62a0a3b">&#9670;&nbsp;</a></span>sampleSRs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt;<a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a>, <a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a>&gt; AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::sampleSRs </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function samples the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> with the specified state action pair. </p>
<p>This function samples the model for simulate experience. The transition and reward functions are used to produce, from the state action pair inserted as arguments, a possible new state with respective reward. The new state is picked from all possible states that the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> allows transitioning to, each with probability equal to the same probability of the transition in the model. After a new state is picked, the reward is the vector of corresponding rewards contained in the reward function.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The state that needs to be sampled. </td></tr>
    <tr><td class="paramname">a</td><td>The action that needs to be sampled.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A tuple containing a new state and a reward. </dd></dl>

</div>
</div>
<a id="af8e0473a7b2bb23c631027b3dc8d4b78"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af8e0473a7b2bb23c631027b3dc8d4b78">&#9670;&nbsp;</a></span>sampleSRs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::sampleSRs </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> *&#160;</td>
          <td class="paramname"><em>s1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a> *&#160;</td>
          <td class="paramname"><em>rews</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function samples the <a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a> with the specified state action pair. </p>
<p>This function is equivalent to sampleSRs(const State &amp;, const Action &amp;).</p>
<p>The only difference is that it allows to output the new State and Rewards into a pre-allocated State and Rewards, avoiding the need for an allocation at every sample.</p>
<p>NO CHECKS for nullptr are done.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The state that needs to be sampled. </td></tr>
    <tr><td class="paramname">a</td><td>The action that needs to be sampled. </td></tr>
    <tr><td class="paramname">s1</td><td>The new state. </td></tr>
    <tr><td class="paramname">rews</td><td>The new rewards. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aad74d3c92a0b513b6690232176bacfdb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aad74d3c92a0b513b6690232176bacfdb">&#9670;&nbsp;</a></span>setDiscount()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::setDiscount </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>d</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets a new discount factor for the Model. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">d</td><td>The new discount factor for the Model. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae40bd14174897a23f17c2081529512a8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae40bd14174897a23f17c2081529512a8">&#9670;&nbsp;</a></span>sync() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::sync </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function syncs the whole <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html" title="This class models CooperativeExperience as a CooperativeModel using Maximum Likelihood. ">CooperativeMaximumLikelihoodModel</a> to the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>. </p>
<p>Since use cases in AI are very varied, one may not want to update its <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html" title="This class models CooperativeExperience as a CooperativeModel using Maximum Likelihood. ">CooperativeMaximumLikelihoodModel</a> for each single transition experienced by the agent. To avoid this we leave to the user the task of syncing between the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> and the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html" title="This class models CooperativeExperience as a CooperativeModel using Maximum Likelihood. ">CooperativeMaximumLikelihoodModel</a>, as he/she sees fit.</p>
<p>After this function is run the transition and reward functions will accurately reflect the state of the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>. </p>

</div>
</div>
<a id="a5bc790743b6d18d11c60e9cbfdd6a501"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5bc790743b6d18d11c60e9cbfdd6a501">&#9670;&nbsp;</a></span>sync() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::sync </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#a597904bffe91df4e1b0d8d11f17f3620">State</a> &amp;&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function syncs a state-action pair to the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The state that needs to be synced. </td></tr>
    <tr><td class="paramname">a</td><td>The action that needs to be synced. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1893bdb7c85e4ba25c61a6c60f69e5d3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1893bdb7c85e4ba25c61a6c60f69e5d3">&#9670;&nbsp;</a></span>sync() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::Factored::MDP::CooperativeMaximumLikelihoodModel::sync </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html#a3a3dcdccdf42909e7d7329bcf10285f6">CooperativeExperience::Indeces</a> &amp;&#160;</td>
          <td class="paramname"><em>indeces</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function syncs the given indeces to the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>. </p>
<p>This function is equivalent to sync(const State &amp;, const Action &amp;), but it avoids recomputing the indeces of the state-action pair. Instead, it uses the ones already computed by the underlying <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> during its record() call.</p>
<p>This works because the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a> and <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html" title="This class models CooperativeExperience as a CooperativeModel using Maximum Likelihood. ">CooperativeMaximumLikelihoodModel</a> use the same factoring of their data structures, and thus the indeces can be used unchanged in both classes.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">indeces</td><td>The indeces provided by the <a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeExperience.html" title="This class keeps track of registered events and rewards. ">CooperativeExperience</a>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>include/AIToolbox/Factored/MDP/<a class="el" href="CooperativeMaximumLikelihoodModel_8hpp_source.html">CooperativeMaximumLikelihoodModel.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceAIToolbox.html">AIToolbox</a></li><li class="navelem"><a class="el" href="namespaceAIToolbox_1_1Factored.html">Factored</a></li><li class="navelem"><a class="el" href="namespaceAIToolbox_1_1Factored_1_1MDP.html">MDP</a></li><li class="navelem"><a class="el" href="classAIToolbox_1_1Factored_1_1MDP_1_1CooperativeMaximumLikelihoodModel.html">CooperativeMaximumLikelihoodModel</a></li>
    <li class="footer">Generated on Tue Mar 24 2020 18:25:06 for AIToolbox by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
