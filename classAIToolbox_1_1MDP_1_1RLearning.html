<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AIToolbox: AIToolbox::MDP::RLearning Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AIToolbox
   </div>
   <div id="projectbrief">A library that offers tools for AI problem solving.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceAIToolbox.html">AIToolbox</a></li><li class="navelem"><a class="el" href="namespaceAIToolbox_1_1MDP.html">MDP</a></li><li class="navelem"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html">RLearning</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classAIToolbox_1_1MDP_1_1RLearning-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">AIToolbox::MDP::RLearning Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>This class represents the <a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html" title="This class represents the RLearning algorithm. ">RLearning</a> algorithm.  
 <a href="classAIToolbox_1_1MDP_1_1RLearning.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="RLearning_8hpp_source.html">RLearning.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab700efdf5598f8540b9454b2e86e7427"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#ab700efdf5598f8540b9454b2e86e7427">RLearning</a> (size_t S, size_t A, double alpha=0.1, double rho=0.1)</td></tr>
<tr class="memdesc:ab700efdf5598f8540b9454b2e86e7427"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic constructor.  <a href="#ab700efdf5598f8540b9454b2e86e7427">More...</a><br /></td></tr>
<tr class="separator:ab700efdf5598f8540b9454b2e86e7427"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e5fcd5dd8c039fd810353884cd2632e"><td class="memTemplParams" colspan="2">template&lt;typename M , typename  = std::enable_if_t&lt;is_generative_model_v&lt;M&gt;&gt;&gt; </td></tr>
<tr class="memitem:a7e5fcd5dd8c039fd810353884cd2632e"><td class="memTemplItemLeft" align="right" valign="top">&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a7e5fcd5dd8c039fd810353884cd2632e">RLearning</a> (const M &amp;model, double alpha=0.1, double rho=0.1)</td></tr>
<tr class="memdesc:a7e5fcd5dd8c039fd810353884cd2632e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic constructor.  <a href="#a7e5fcd5dd8c039fd810353884cd2632e">More...</a><br /></td></tr>
<tr class="separator:a7e5fcd5dd8c039fd810353884cd2632e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaceb3a94aa4956cc67ebfa7f5b984562"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#aaceb3a94aa4956cc67ebfa7f5b984562">setAlphaLearningRate</a> (double a)</td></tr>
<tr class="memdesc:aaceb3a94aa4956cc67ebfa7f5b984562"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the learning rate parameter for the QFunction.  <a href="#aaceb3a94aa4956cc67ebfa7f5b984562">More...</a><br /></td></tr>
<tr class="separator:aaceb3a94aa4956cc67ebfa7f5b984562"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a245884650873059b30c12f3f8985ea32"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a245884650873059b30c12f3f8985ea32">getAlphaLearningRate</a> () const</td></tr>
<tr class="memdesc:a245884650873059b30c12f3f8985ea32"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function will return the current set alpha learning rate parameter.  <a href="#a245884650873059b30c12f3f8985ea32">More...</a><br /></td></tr>
<tr class="separator:a245884650873059b30c12f3f8985ea32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f2970a329a36d14eab9ee57c724928d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a4f2970a329a36d14eab9ee57c724928d">setRhoLearningRate</a> (double r)</td></tr>
<tr class="memdesc:a4f2970a329a36d14eab9ee57c724928d"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the learning rate parameter for the average reward.  <a href="#a4f2970a329a36d14eab9ee57c724928d">More...</a><br /></td></tr>
<tr class="separator:a4f2970a329a36d14eab9ee57c724928d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d73abbe40d4225329d69aa72a28986e"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a0d73abbe40d4225329d69aa72a28986e">getRhoLearningRate</a> () const</td></tr>
<tr class="memdesc:a0d73abbe40d4225329d69aa72a28986e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function will return the current set rho learning rate parameter.  <a href="#a0d73abbe40d4225329d69aa72a28986e">More...</a><br /></td></tr>
<tr class="separator:a0d73abbe40d4225329d69aa72a28986e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b26229b9eb70601f6d2eae45939b4fb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a0b26229b9eb70601f6d2eae45939b4fb">stepUpdateQ</a> (size_t s, size_t a, size_t s1, double rew)</td></tr>
<tr class="memdesc:a0b26229b9eb70601f6d2eae45939b4fb"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function updates the internal QFunction using the discount set during construction.  <a href="#a0b26229b9eb70601f6d2eae45939b4fb">More...</a><br /></td></tr>
<tr class="separator:a0b26229b9eb70601f6d2eae45939b4fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f0185f3d4a68a12e011f39de762b4cc"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a2f0185f3d4a68a12e011f39de762b4cc">getS</a> () const</td></tr>
<tr class="memdesc:a2f0185f3d4a68a12e011f39de762b4cc"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of states on which <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> is working.  <a href="#a2f0185f3d4a68a12e011f39de762b4cc">More...</a><br /></td></tr>
<tr class="separator:a2f0185f3d4a68a12e011f39de762b4cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1777127a7b0702d63c7cc64920e75f9"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#ab1777127a7b0702d63c7cc64920e75f9">getA</a> () const</td></tr>
<tr class="memdesc:ab1777127a7b0702d63c7cc64920e75f9"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of actions on which <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> is working.  <a href="#ab1777127a7b0702d63c7cc64920e75f9">More...</a><br /></td></tr>
<tr class="separator:ab1777127a7b0702d63c7cc64920e75f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a385d4cd10ba785482b91bf7aea3ba77c"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a385d4cd10ba785482b91bf7aea3ba77c">getQFunction</a> () const</td></tr>
<tr class="memdesc:a385d4cd10ba785482b91bf7aea3ba77c"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns a reference to the internal QFunction.  <a href="#a385d4cd10ba785482b91bf7aea3ba77c">More...</a><br /></td></tr>
<tr class="separator:a385d4cd10ba785482b91bf7aea3ba77c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b2b1e4e28d00178d67540f920e6013e"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a6b2b1e4e28d00178d67540f920e6013e">getAverageReward</a> () const</td></tr>
<tr class="memdesc:a6b2b1e4e28d00178d67540f920e6013e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the learned average reward.  <a href="#a6b2b1e4e28d00178d67540f920e6013e">More...</a><br /></td></tr>
<tr class="separator:a6b2b1e4e28d00178d67540f920e6013e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ec4c03e26c25e3a56efafca0c2261fa"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a4ec4c03e26c25e3a56efafca0c2261fa">setQFunction</a> (const <a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a> &amp;qfun)</td></tr>
<tr class="memdesc:a4ec4c03e26c25e3a56efafca0c2261fa"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function allows to directly set the internal QFunction.  <a href="#a4ec4c03e26c25e3a56efafca0c2261fa">More...</a><br /></td></tr>
<tr class="separator:a4ec4c03e26c25e3a56efafca0c2261fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This class represents the <a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html" title="This class represents the RLearning algorithm. ">RLearning</a> algorithm. </p>
<p>This algorithm is an analogue to <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a>, when one wishes to learn to maximize average reward in infinitely long episodes, rather than discounted reward. Such policies are called T-optimal policies.</p>
<p>Indeed, <a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html" title="This class represents the RLearning algorithm. ">RLearning</a> makes the point that discount is an unnecessary and harmful abstraction in these cases, and that it is generally only used to bound the expected reward when acting infinitely. At the same time, discounting can result in policies which are unnecessarily greedy and don't maximize average reward over time.</p>
<p>Thus, the update rule for the QFunction is slightly altered, so that, for each state-action pair, we learn the expected <em>average-adjusted</em> reward (present and future), i.e. the reward minus the average reward, which is the measure we want to learn to act upon. To do so, we also need to learn the average reward.</p>
<p>The two elements are learned side by side, and this is why here we have two separate learning rates; one for the QFunction and the other for the average reward. Note that the original paper calls these respectively the beta and alpha learning rate. Here, to keep consistency between methods, we call these alpha and rho. We also rename the standard setLearningRate() function to make sure that users understand what they are setting.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#aaceb3a94aa4956cc67ebfa7f5b984562" title="This function sets the learning rate parameter for the QFunction. ">setAlphaLearningRate(double)</a> </dd>
<dd>
<a class="el" href="classAIToolbox_1_1MDP_1_1RLearning.html#a4f2970a329a36d14eab9ee57c724928d" title="This function sets the learning rate parameter for the average reward. ">setRhoLearningRate(double)</a></dd></dl>
<p>This algorithm does not actually need to sample from the input model, and so it can be a good algorithm to apply in real world scenarios, where there would be no way to reproduce the world's behavior aside from actually trying out actions. However it is needed to know the size of the state space, the size of the action space and the discount factor of the problem. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ab700efdf5598f8540b9454b2e86e7427"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab700efdf5598f8540b9454b2e86e7427">&#9670;&nbsp;</a></span>RLearning() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">AIToolbox::MDP::RLearning::RLearning </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>S</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>rho</em> = <code>0.1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic constructor. </p>
<p>Both learning rates must be &gt; 0.0 and &lt;= 1.0, otherwise the constructor will throw an std::invalid_argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">S</td><td>The size of the state space. </td></tr>
    <tr><td class="paramname">A</td><td>The size of the action space. </td></tr>
    <tr><td class="paramname">alpha</td><td>The learning rate for the QFunction. </td></tr>
    <tr><td class="paramname">rho</td><td>The learning rate for the average reward. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7e5fcd5dd8c039fd810353884cd2632e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7e5fcd5dd8c039fd810353884cd2632e">&#9670;&nbsp;</a></span>RLearning() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename M , typename &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">AIToolbox::MDP::RLearning::RLearning </td>
          <td>(</td>
          <td class="paramtype">const M &amp;&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>rho</em> = <code>0.1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic constructor. </p>
<p>Both learning rates must be &gt; 0.0 and &lt;= 1.0, otherwise the constructor will throw an std::invalid_argument.</p>
<p>This constructor copies the S and A and discount parameters from the supplied model. It does not keep the reference, so if the discount needs to change you'll need to update it here manually too.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The <a class="el" href="namespaceAIToolbox_1_1MDP.html">MDP</a> model that <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> will use as a base. </td></tr>
    <tr><td class="paramname">alpha</td><td>The learning rate for the QFunction. </td></tr>
    <tr><td class="paramname">rho</td><td>The learning rate for the average reward. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="ab1777127a7b0702d63c7cc64920e75f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1777127a7b0702d63c7cc64920e75f9">&#9670;&nbsp;</a></span>getA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t AIToolbox::MDP::RLearning::getA </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the number of actions on which <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> is working. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of actions. </dd></dl>

</div>
</div>
<a id="a245884650873059b30c12f3f8985ea32"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a245884650873059b30c12f3f8985ea32">&#9670;&nbsp;</a></span>getAlphaLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::MDP::RLearning::getAlphaLearningRate </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function will return the current set alpha learning rate parameter. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set alpha learning rate parameter. </dd></dl>

</div>
</div>
<a id="a6b2b1e4e28d00178d67540f920e6013e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b2b1e4e28d00178d67540f920e6013e">&#9670;&nbsp;</a></span>getAverageReward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::MDP::RLearning::getAverageReward </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the learned average reward. </p>
<dl class="section return"><dt>Returns</dt><dd>The learned average reward. </dd></dl>

</div>
</div>
<a id="a385d4cd10ba785482b91bf7aea3ba77c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a385d4cd10ba785482b91bf7aea3ba77c">&#9670;&nbsp;</a></span>getQFunction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a>&amp; AIToolbox::MDP::RLearning::getQFunction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns a reference to the internal QFunction. </p>
<p>The returned reference can be used to build Policies, for example <a class="el" href="classAIToolbox_1_1MDP_1_1QGreedyPolicy.html" title="This class models a greedy policy through a QFunction. ">MDP::QGreedyPolicy</a>.</p>
<dl class="section return"><dt>Returns</dt><dd>The internal QFunction. </dd></dl>

</div>
</div>
<a id="a0d73abbe40d4225329d69aa72a28986e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0d73abbe40d4225329d69aa72a28986e">&#9670;&nbsp;</a></span>getRhoLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::MDP::RLearning::getRhoLearningRate </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function will return the current set rho learning rate parameter. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set rho learning rate parameter. </dd></dl>

</div>
</div>
<a id="a2f0185f3d4a68a12e011f39de762b4cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f0185f3d4a68a12e011f39de762b4cc">&#9670;&nbsp;</a></span>getS()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t AIToolbox::MDP::RLearning::getS </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the number of states on which <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> is working. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of states. </dd></dl>

</div>
</div>
<a id="aaceb3a94aa4956cc67ebfa7f5b984562"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaceb3a94aa4956cc67ebfa7f5b984562">&#9670;&nbsp;</a></span>setAlphaLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::RLearning::setAlphaLearningRate </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>a</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the learning rate parameter for the QFunction. </p>
<p>The learning parameter determines the speed at which the QFunction is modified with respect to new data. In fully deterministic environments (such as an agent moving through a grid, for example), this parameter can be safely set to 1.0 for maximum learning.</p>
<p>On the other side, in stochastic environments, in order to converge this parameter should be higher when first starting to learn, and decrease slowly over time.</p>
<p>Otherwise it can be kept somewhat high if the environment dynamics change progressively, and the algorithm will adapt accordingly. The final behavior of <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> is very dependent on this parameter.</p>
<p>The learning rate parameter must be &gt; 0.0 and &lt;= 1.0, otherwise the function will throw an std::invalid_argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">a</td><td>The new alpha learning rate parameter. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4ec4c03e26c25e3a56efafca0c2261fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4ec4c03e26c25e3a56efafca0c2261fa">&#9670;&nbsp;</a></span>setQFunction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::RLearning::setQFunction </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a> &amp;&#160;</td>
          <td class="paramname"><em>qfun</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function allows to directly set the internal QFunction. </p>
<p>This can be useful in order to use a QFunction that has already been computed elsewhere. <a class="el" href="classAIToolbox_1_1MDP_1_1SARSAL.html" title="This class represents the SARSAL algorithm. ">SARSAL</a> will then continue building upon it.</p>
<p>This is used for example in the <a class="el" href="classAIToolbox_1_1MDP_1_1Dyna2.html" title="This class represents the Dyna2 algorithm. ">Dyna2</a> algorithm.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">qfun</td><td>The new QFunction to set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4f2970a329a36d14eab9ee57c724928d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f2970a329a36d14eab9ee57c724928d">&#9670;&nbsp;</a></span>setRhoLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::RLearning::setRhoLearningRate </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>r</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the learning rate parameter for the average reward. </p>
<p>The learning parameter determines the speed at which the average reward is modified with respect to new data.</p>
<p>The learning rate parameter must be &gt; 0.0 and &lt;= 1.0, otherwise the function will throw an std::invalid_argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">r</td><td>The new rho learning rate parameter. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a0b26229b9eb70601f6d2eae45939b4fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b26229b9eb70601f6d2eae45939b4fb">&#9670;&nbsp;</a></span>stepUpdateQ()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::RLearning::stepUpdateQ </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>rew</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function updates the internal QFunction using the discount set during construction. </p>
<p>This function takes a single experience point and uses it to update the QFunction. This is a very efficient method to keep the QFunction up to date with the latest experience.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The previous state. </td></tr>
    <tr><td class="paramname">a</td><td>The action performed. </td></tr>
    <tr><td class="paramname">s1</td><td>The new state. </td></tr>
    <tr><td class="paramname">rew</td><td>The reward obtained. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>include/AIToolbox/MDP/Algorithms/<a class="el" href="RLearning_8hpp_source.html">RLearning.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Mar 6 2020 12:58:22 for AIToolbox by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
