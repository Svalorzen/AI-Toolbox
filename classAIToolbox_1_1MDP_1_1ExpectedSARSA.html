<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AIToolbox: AIToolbox::MDP::ExpectedSARSA Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AIToolbox
   </div>
   <div id="projectbrief">A library that offers tools for AI problem solving.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceAIToolbox.html">AIToolbox</a></li><li class="navelem"><a class="el" href="namespaceAIToolbox_1_1MDP.html">MDP</a></li><li class="navelem"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html">ExpectedSARSA</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classAIToolbox_1_1MDP_1_1ExpectedSARSA-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">AIToolbox::MDP::ExpectedSARSA Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>This class represents the <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> algorithm.  
 <a href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="ExpectedSARSA_8hpp_source.html">ExpectedSARSA.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a0da3d133179c0cd5cba29ee51c18d65a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#a0da3d133179c0cd5cba29ee51c18d65a">ExpectedSARSA</a> (<a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a> &amp;qfun, const <a class="el" href="classAIToolbox_1_1MDP_1_1PolicyInterface.html">PolicyInterface</a> &amp;policy, double discount=0.0, double alpha=0.1)</td></tr>
<tr class="memdesc:a0da3d133179c0cd5cba29ee51c18d65a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic constructor.  <a href="#a0da3d133179c0cd5cba29ee51c18d65a">More...</a><br /></td></tr>
<tr class="separator:a0da3d133179c0cd5cba29ee51c18d65a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3476556bf504f33859254fc4e77ed40"><td class="memTemplParams" colspan="2">template&lt;typename M , typename  = std::enable_if_t&lt;is_generative_model&lt;M&gt;::value&gt;&gt; </td></tr>
<tr class="memitem:ab3476556bf504f33859254fc4e77ed40"><td class="memTemplItemLeft" align="right" valign="top">&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#ab3476556bf504f33859254fc4e77ed40">ExpectedSARSA</a> (<a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a> &amp;qfun, const <a class="el" href="classAIToolbox_1_1MDP_1_1PolicyInterface.html">PolicyInterface</a> &amp;policy, const M &amp;model, double alpha=0.1)</td></tr>
<tr class="memdesc:ab3476556bf504f33859254fc4e77ed40"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic constructor.  <a href="#ab3476556bf504f33859254fc4e77ed40">More...</a><br /></td></tr>
<tr class="separator:ab3476556bf504f33859254fc4e77ed40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf90b06cdc445f12d11808bfb9ef790d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#adf90b06cdc445f12d11808bfb9ef790d">setLearningRate</a> (double a)</td></tr>
<tr class="memdesc:adf90b06cdc445f12d11808bfb9ef790d"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the learning rate parameter.  <a href="#adf90b06cdc445f12d11808bfb9ef790d">More...</a><br /></td></tr>
<tr class="separator:adf90b06cdc445f12d11808bfb9ef790d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51d12f22aa8300221023d435568c4790"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#a51d12f22aa8300221023d435568c4790">getLearningRate</a> () const</td></tr>
<tr class="memdesc:a51d12f22aa8300221023d435568c4790"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function will return the current set learning rate parameter.  <a href="#a51d12f22aa8300221023d435568c4790">More...</a><br /></td></tr>
<tr class="separator:a51d12f22aa8300221023d435568c4790"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3683c2f1a75ec18d148586720218e0f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#ac3683c2f1a75ec18d148586720218e0f">setDiscount</a> (double d)</td></tr>
<tr class="memdesc:ac3683c2f1a75ec18d148586720218e0f"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the new discount parameter.  <a href="#ac3683c2f1a75ec18d148586720218e0f">More...</a><br /></td></tr>
<tr class="separator:ac3683c2f1a75ec18d148586720218e0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd296bff229c404761a4aa81fcf1c083"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#afd296bff229c404761a4aa81fcf1c083">getDiscount</a> () const</td></tr>
<tr class="memdesc:afd296bff229c404761a4aa81fcf1c083"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the currently set discount parameter.  <a href="#afd296bff229c404761a4aa81fcf1c083">More...</a><br /></td></tr>
<tr class="separator:afd296bff229c404761a4aa81fcf1c083"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa23be2db0c2ce5c4b113c3a8d36813b9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#aa23be2db0c2ce5c4b113c3a8d36813b9">stepUpdateQ</a> (size_t s, size_t a, size_t s1, double rew)</td></tr>
<tr class="memdesc:aa23be2db0c2ce5c4b113c3a8d36813b9"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function updates the internal QFunction using the discount set during construction.  <a href="#aa23be2db0c2ce5c4b113c3a8d36813b9">More...</a><br /></td></tr>
<tr class="separator:aa23be2db0c2ce5c4b113c3a8d36813b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae04d2a69216a16371836e2bba134a963"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#ae04d2a69216a16371836e2bba134a963">getS</a> () const</td></tr>
<tr class="memdesc:ae04d2a69216a16371836e2bba134a963"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of states on which <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> is working.  <a href="#ae04d2a69216a16371836e2bba134a963">More...</a><br /></td></tr>
<tr class="separator:ae04d2a69216a16371836e2bba134a963"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e894f10e3cdeff0273c284a9355e661"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#a1e894f10e3cdeff0273c284a9355e661">getA</a> () const</td></tr>
<tr class="memdesc:a1e894f10e3cdeff0273c284a9355e661"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the number of actions on which <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> is working.  <a href="#a1e894f10e3cdeff0273c284a9355e661">More...</a><br /></td></tr>
<tr class="separator:a1e894f10e3cdeff0273c284a9355e661"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a216bdde7542befbd8b88c8026666c7fe"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#a216bdde7542befbd8b88c8026666c7fe">getQFunction</a> () const</td></tr>
<tr class="memdesc:a216bdde7542befbd8b88c8026666c7fe"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns a reference to the internal QFunction.  <a href="#a216bdde7542befbd8b88c8026666c7fe">More...</a><br /></td></tr>
<tr class="separator:a216bdde7542befbd8b88c8026666c7fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7bfdbc1045bc3b3eaba3ef89dfa96fe"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classAIToolbox_1_1MDP_1_1PolicyInterface.html">PolicyInterface</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html#ae7bfdbc1045bc3b3eaba3ef89dfa96fe">getPolicy</a> () const</td></tr>
<tr class="memdesc:ae7bfdbc1045bc3b3eaba3ef89dfa96fe"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns a reference to the policy used by <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a>.  <a href="#ae7bfdbc1045bc3b3eaba3ef89dfa96fe">More...</a><br /></td></tr>
<tr class="separator:ae7bfdbc1045bc3b3eaba3ef89dfa96fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This class represents the <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> algorithm. </p>
<p>This algorithm is a subtle improvement over the <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a> algorithm.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a></dd></dl>
<p>The difference between this algorithm and the original <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a> algorithm lies in the value used to approximate the value for the next timestep. In standard <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a> this value is directly taken as the current approximation of the value of the QFunction for the newly sampled state and the next action to be performed (the final "SA" in SAR"SA").</p>
<p>In Expected <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a> this value is instead replaced by the expected value for the newly sampled state, given the policy from which we will sample the next action. In this sense Expected <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a> is more similar to <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a>: where <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> uses the max over the QFunction for the next state, Expected <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a> uses the future expectation over the current online policy.</p>
<p>This reduces considerably the variance of the updates performed, which in turn allows to somewhat increase the learning rate for the method, which allows Expected <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a> to learn faster than simple <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a>. All guarantees of normal <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a> are maintained. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a0da3d133179c0cd5cba29ee51c18d65a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0da3d133179c0cd5cba29ee51c18d65a">&#9670;&nbsp;</a></span>ExpectedSARSA() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">AIToolbox::MDP::ExpectedSARSA::ExpectedSARSA </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a> &amp;&#160;</td>
          <td class="paramname"><em>qfun</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classAIToolbox_1_1MDP_1_1PolicyInterface.html">PolicyInterface</a> &amp;&#160;</td>
          <td class="paramname"><em>policy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>discount</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic constructor. </p>
<p>Note that differently from normal <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a>, <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> does not self-contain its own QFunction. This is because many policies are implemented in terms of a QFunction continuously updated by a method (e.g. <a class="el" href="classAIToolbox_1_1MDP_1_1QGreedyPolicy.html" title="This class models a greedy policy through a QFunction. ">QGreedyPolicy</a>).</p>
<p>At the same time <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> needs this policy in order to be able to perform its expected value computation. In order to avoid having a chicken and egg problem, <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> takes a QFunction as parameter to allow the user to create it an use the same one for both <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> and the policy.</p>
<p>The learning rate must be &gt; 0.0 and &lt;= 1.0, otherwise the constructor will throw an std::invalid_argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">qfun</td><td>The QFunction underlying the <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> algorithm. </td></tr>
    <tr><td class="paramname">policy</td><td>The policy used to select actions. </td></tr>
    <tr><td class="paramname">discount</td><td>The discount of the underlying <a class="el" href="namespaceAIToolbox_1_1MDP.html">MDP</a> model. </td></tr>
    <tr><td class="paramname">alpha</td><td>The learning rate of the <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> method. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab3476556bf504f33859254fc4e77ed40"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3476556bf504f33859254fc4e77ed40">&#9670;&nbsp;</a></span>ExpectedSARSA() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename M , typename &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">AIToolbox::MDP::ExpectedSARSA::ExpectedSARSA </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a> &amp;&#160;</td>
          <td class="paramname"><em>qfun</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classAIToolbox_1_1MDP_1_1PolicyInterface.html">PolicyInterface</a> &amp;&#160;</td>
          <td class="paramname"><em>policy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const M &amp;&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic constructor. </p>
<p>Note that differently from normal <a class="el" href="classAIToolbox_1_1MDP_1_1SARSA.html" title="This class represents the SARSA algorithm. ">SARSA</a>, <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> does not self-contain its own QFunction. This is because many policies are implemented in terms of a QFunction continuously updated by a method (e.g. <a class="el" href="classAIToolbox_1_1MDP_1_1QGreedyPolicy.html" title="This class models a greedy policy through a QFunction. ">QGreedyPolicy</a>).</p>
<p>At the same time <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> needs this policy in order to be able to perform its expected value computation. In order to avoid having a chicken and egg problem, <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> takes a QFunction as parameter to allow the user to create it an use the same one for both <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> and the policy.</p>
<p>The learning rate must be &gt; 0.0 and &lt;= 1.0, otherwise the constructor will throw an std::invalid_argument.</p>
<p>This constructor copies the discount parameter from the supplied model. It does not keep the reference, so if the discount needs to change you'll need to update it here manually too.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">qfun</td><td>The QFunction underlying the <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> algorithm. </td></tr>
    <tr><td class="paramname">policy</td><td>The policy used to select actions. </td></tr>
    <tr><td class="paramname">model</td><td>The <a class="el" href="namespaceAIToolbox_1_1MDP.html">MDP</a> model that <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> will use as a base. </td></tr>
    <tr><td class="paramname">alpha</td><td>The learning rate of the <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> method. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a1e894f10e3cdeff0273c284a9355e661"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e894f10e3cdeff0273c284a9355e661">&#9670;&nbsp;</a></span>getA()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t AIToolbox::MDP::ExpectedSARSA::getA </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the number of actions on which <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> is working. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of actions. </dd></dl>

</div>
</div>
<a id="afd296bff229c404761a4aa81fcf1c083"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd296bff229c404761a4aa81fcf1c083">&#9670;&nbsp;</a></span>getDiscount()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::MDP::ExpectedSARSA::getDiscount </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the currently set discount parameter. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set discount parameter. </dd></dl>

</div>
</div>
<a id="a51d12f22aa8300221023d435568c4790"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a51d12f22aa8300221023d435568c4790">&#9670;&nbsp;</a></span>getLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double AIToolbox::MDP::ExpectedSARSA::getLearningRate </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function will return the current set learning rate parameter. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set learning rate parameter. </dd></dl>

</div>
</div>
<a id="ae7bfdbc1045bc3b3eaba3ef89dfa96fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae7bfdbc1045bc3b3eaba3ef89dfa96fe">&#9670;&nbsp;</a></span>getPolicy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classAIToolbox_1_1MDP_1_1PolicyInterface.html">PolicyInterface</a>&amp; AIToolbox::MDP::ExpectedSARSA::getPolicy </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns a reference to the policy used by <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>The internal policy reference. </dd></dl>

</div>
</div>
<a id="a216bdde7542befbd8b88c8026666c7fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a216bdde7542befbd8b88c8026666c7fe">&#9670;&nbsp;</a></span>getQFunction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespaceAIToolbox_1_1MDP.html#a7511ad35cec2e20bf392458125e28ebc">QFunction</a>&amp; AIToolbox::MDP::ExpectedSARSA::getQFunction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns a reference to the internal QFunction. </p>
<p>The returned reference can be used to build Policies, for example <a class="el" href="classAIToolbox_1_1MDP_1_1QGreedyPolicy.html" title="This class models a greedy policy through a QFunction. ">MDP::QGreedyPolicy</a>.</p>
<dl class="section return"><dt>Returns</dt><dd>The internal QFunction. </dd></dl>

</div>
</div>
<a id="ae04d2a69216a16371836e2bba134a963"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae04d2a69216a16371836e2bba134a963">&#9670;&nbsp;</a></span>getS()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t AIToolbox::MDP::ExpectedSARSA::getS </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the number of states on which <a class="el" href="classAIToolbox_1_1MDP_1_1QLearning.html" title="This class represents the QLearning algorithm. ">QLearning</a> is working. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of states. </dd></dl>

</div>
</div>
<a id="ac3683c2f1a75ec18d148586720218e0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac3683c2f1a75ec18d148586720218e0f">&#9670;&nbsp;</a></span>setDiscount()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::ExpectedSARSA::setDiscount </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>d</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the new discount parameter. </p>
<p>The discount parameter controls the amount that future rewards are considered by <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a>. If 1, then any reward is the same, if obtained now or in a million timesteps. Thus the algorithm will optimize overall reward accretion. When less than 1, rewards obtained in the presents are valued more than future rewards.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">d</td><td>The new discount factor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="adf90b06cdc445f12d11808bfb9ef790d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adf90b06cdc445f12d11808bfb9ef790d">&#9670;&nbsp;</a></span>setLearningRate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::ExpectedSARSA::setLearningRate </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>a</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the learning rate parameter. </p>
<p>The learning parameter determines the speed at which the QFunction is modified with respect to new data. In fully deterministic environments (such as an agent moving through a grid, for example), this parameter can be safely set to 1.0 for maximum learning.</p>
<p>On the other side, in stochastic environments, in order to converge this parameter should be higher when first starting to learn, and decrease slowly over time.</p>
<p>Otherwise it can be kept somewhat high if the environment dynamics change progressively, and the algorithm will adapt accordingly. The final behaviour of <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> is very dependent on this parameter.</p>
<p>The learning rate parameter must be &gt; 0.0 and &lt;= 1.0, otherwise the function will throw an std::invalid_argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">a</td><td>The new learning rate parameter. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa23be2db0c2ce5c4b113c3a8d36813b9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa23be2db0c2ce5c4b113c3a8d36813b9">&#9670;&nbsp;</a></span>stepUpdateQ()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::MDP::ExpectedSARSA::stepUpdateQ </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>s1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>rew</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function updates the internal QFunction using the discount set during construction. </p>
<p>This function takes a single experience point and uses it to update the QFunction. This is a very efficient method to keep the QFunction up to date with the latest experience.</p>
<p>Keep in mind that, since <a class="el" href="classAIToolbox_1_1MDP_1_1ExpectedSARSA.html" title="This class represents the ExpectedSARSA algorithm. ">ExpectedSARSA</a> needs to compute the QFunction for the currently used policy, it needs to know two consecutive state-action pairs, in order to correctly relate how the policy acts from state to state.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The previous state. </td></tr>
    <tr><td class="paramname">a</td><td>The action performed. </td></tr>
    <tr><td class="paramname">s1</td><td>The new state. </td></tr>
    <tr><td class="paramname">rew</td><td>The reward obtained. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>include/AIToolbox/MDP/Algorithms/<a class="el" href="ExpectedSARSA_8hpp_source.html">ExpectedSARSA.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Jun 8 2018 12:06:53 for AIToolbox by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
